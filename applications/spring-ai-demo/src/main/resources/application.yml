spring:
  application:
    name: java-demo
  ai:
    chat:
      observations:
        log-prompt: true       # Include prompt content in tracing (disabled by default for privacy)
        log-completion: true   # Include completion content in tracing (disabled by default)

management:
  tracing:
    sampling:
      probability: 1.0    # Sample 100% of requests for full tracing (adjust in production as needed)
  observations:
    annotations:
      enabled: true       # Enable @Observed (if you use observation annotations in code)

otel:
  logs:
    exporter: none        # Disable OTLP log export (Langfuse expects traces only)

---

spring:
  config:
    activate:
      on-profile: google
  ai:
    google:
      genai:
        chat:
          options:
            model: gemini-2.0-flash

---

spring:
  config:
    activate:
      on-profile: openai
  ai:
    openai:
      chat:
        options:
          model: gpt-4o-mini
